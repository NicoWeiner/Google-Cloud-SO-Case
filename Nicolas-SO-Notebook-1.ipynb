{"nbformat_minor": 2, "cells": [{"source": "# Introduction", "cell_type": "markdown", "metadata": {}}, {"source": "Most code is interpreted from: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#\n\nFirst, I prepare the necessary environment as shown in Riccardo's Demo file but adapt it to my project's paths:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "import pyspark\nimport sys", "outputs": [], "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "src_gs = 'gs://stackoverflow_data_nicolas'", "outputs": [], "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "spark", "outputs": [{"execution_count": 3, "output_type": "execute_result", "data": {"text/plain": "<pyspark.sql.session.SparkSession at 0x7ff8c0eb2690>", "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://nicolas-cluster-m.europe-west2-a.c.nicolas-stackoverflow-project.internal:4041\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.3.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "}, "metadata": {}}], "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "SparkSession", "outputs": [{"execution_count": 4, "output_type": "execute_result", "data": {"text/plain": "pyspark.sql.session.SparkSession"}, "metadata": {}}], "metadata": {}}, {"source": "Now import the post_answer and post_question datasets from the bucket:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "SOanswers_df = spark.read.option('header', True).csv(path = src_gs + '/post_answers*')", "outputs": [], "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "SOquestions_df = spark.read.option('header', True).csv(path = src_gs + '/post_questions*')", "outputs": [], "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "import pyspark.sql.functions as f", "outputs": [], "metadata": {}}, {"source": "# Question 1: - What percentage of questions have been answered over the years?", "cell_type": "markdown", "metadata": {}}, {"source": "First, I explore SOanswers.df and SOquestions.df:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "SOanswers_df.dtypes", "outputs": [{"execution_count": 8, "output_type": "execute_result", "data": {"text/plain": "[('id', 'string'),\n ('title', 'string'),\n ('body', 'string'),\n ('accepted_answer_id', 'string'),\n ('answer_count', 'string'),\n ('comment_count', 'string'),\n ('community_owned_date', 'string'),\n ('creation_date', 'string'),\n ('favorite_count', 'string'),\n ('last_activity_date', 'string'),\n ('last_edit_date', 'string'),\n ('last_editor_display_name', 'string'),\n ('last_editor_user_id', 'string'),\n ('owner_display_name', 'string'),\n ('owner_user_id', 'string'),\n ('parent_id', 'string'),\n ('post_type_id', 'string'),\n ('score', 'string'),\n ('tags', 'string'),\n ('view_count', 'string')]"}, "metadata": {}}], "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "SOquestions_df.dtypes", "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "[('id', 'string'),\n ('title', 'string'),\n ('body', 'string'),\n ('accepted_answer_id', 'string'),\n ('answer_count', 'string'),\n ('comment_count', 'string'),\n ('community_owned_date', 'string'),\n ('creation_date', 'string'),\n ('favorite_count', 'string'),\n ('last_activity_date', 'string'),\n ('last_edit_date', 'string'),\n ('last_editor_display_name', 'string'),\n ('last_editor_user_id', 'string'),\n ('owner_display_name', 'string'),\n ('owner_user_id', 'string'),\n ('parent_id', 'string'),\n ('post_type_id', 'string'),\n ('score', 'string'),\n ('tags', 'string'),\n ('view_count', 'string')]"}, "metadata": {}}], "metadata": {}}, {"source": "Considering that SOanswers and SOquestions have a column called answer_count, I create a new df with this column, the ID column and creation_date which I reformat from string to date: (https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.to_date)", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "Q1_answers = SOanswers_df.select(f.col('id'),f.year(f.to_date('creation_date')).alias('year'),f.col('answer_count'))\nQ1_answers", "outputs": [{"execution_count": 10, "output_type": "execute_result", "data": {"text/plain": "DataFrame[id: string, year: int, answer_count: string]"}, "metadata": {}}], "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "Q1_questions = SOquestions_df.select(f.col('id'),f.year(f.to_date('creation_date')).alias('year'),f.col('answer_count'))\nQ1_questions", "outputs": [{"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "DataFrame[id: string, year: int, answer_count: string]"}, "metadata": {}}], "metadata": {}}, {"source": "\nNow, I group the dates into one year respectively, aggregate the answer_count and create a new column which all answers excluding any null values, hence excluding where no answer was given:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "Q1_answers_new = Q1_answers.groupby(['year']).agg(f.count('answer_count').alias('number of answers'), f.count((f.when((f.col(\"answer_count\")!='0')&(f.col(\"answer_count\")!='null'),True))).alias('excluding no answers'))\nQ1_answers_new\n", "outputs": [{"execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "DataFrame[year: int, number of answers: bigint, excluding no answers: bigint]"}, "metadata": {}}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "Q1_questions_new = Q1_questions.groupby(['year']).agg(f.count('answer_count').alias('number of answers'), f.count((f.when((f.col(\"answer_count\")!='0')&(f.col(\"answer_count\")!='null'),True))).alias('excluding no answers'))\nQ1_questions_new", "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "DataFrame[year: int, number of answers: bigint, excluding no answers: bigint]"}, "metadata": {}}], "metadata": {}}, {"source": "Now, I create a new column with the percentage of answered questions whereby I divide total answers by 'excluding no answers' * 100. This answers Q1 considering the SOanswers datasets. To exclude outliers, the filter() function is used showing only entries with more than 100 results. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "Q1_answers_final = Q1_answers_new.withColumn('percentage answered questions', (f.col('excluding no answers')/f.col('number of answers'))*100).filter(f.col('number of answers')>100).sort(f.col('year').desc()).show(10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+-----------------+--------------------+-----------------------------+\n|year|number of answers|excluding no answers|percentage answered questions|\n+----+-----------------+--------------------+-----------------------------+\n|2019|             2466|                2466|                        100.0|\n|2018|             3900|                3875|            99.35897435897436|\n|2017|             3782|                3782|                        100.0|\n|2016|             4224|                4224|                        100.0|\n|2015|             4601|                4601|                        100.0|\n|2014|             5167|                5167|                        100.0|\n|2013|             5299|                5299|                        100.0|\n|2012|             4661|                4660|            99.97854537652864|\n|2011|             4732|                4732|                        100.0|\n|2010|             8593|                8593|                        100.0|\n+----+-----------------+--------------------+-----------------------------+\nonly showing top 10 rows\n\n"}], "metadata": {}}, {"source": "Now, I create a new column with the percentage of answered questions whereby I divide total answers by 'excluding no answers' * 100. This answers Q1 considering the SOquestions datasets. To exclude outliers, the filter() function is used showing only entries with more than 100 results. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "Q1_questions_final = Q1_questions_new.withColumn('percentage answered questions', (f.col('excluding no answers')/f.col('number of answers'))*100).filter(f.col('number of answers')>100).sort(f.col('year').desc()).show(10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+-----------------+--------------------+-----------------------------+\n|year|number of answers|excluding no answers|percentage answered questions|\n+----+-----------------+--------------------+-----------------------------+\n|2019|           111746|               70289|            62.90068548314929|\n|2018|           153392|              116049|            75.65518410347345|\n|2017|           165595|              137416|            82.98318185935565|\n|2016|           178489|              151488|            84.87245712620945|\n|2015|           184274|              159957|            86.80388985966549|\n|2014|           180330|              160012|             88.7328786114346|\n|2013|           185347|              170456|            91.96588021386913|\n|2012|           172987|              164344|            95.00367079607138|\n|2011|           150224|              146571|             97.5682980083076|\n|2010|           104107|              103206|            99.13454426695611|\n+----+-----------------+--------------------+-----------------------------+\nonly showing top 10 rows\n\n"}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}